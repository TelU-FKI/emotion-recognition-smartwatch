import argparse
import yaml
import numpy as np
from collections import defaultdict
from sklearn import linear_model, metrics, model_selection, preprocessing
from sklearn.dummy import DummyClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import RepeatedStratifiedKFold
from keras.models import Sequential
from keras.layers import Conv1D, GlobalMaxPooling1D, Dense
from keras.utils import to_categorical

SEED = 1
np.random.seed(SEED)

def main():
    '''
    Run as:
    python user_lift.py -mo features/features_mo* -mw features/features_mw* -mu features/features_mu*
    Takes features generated by extract_windows.py script, runs classifier, and prints accuracy results.
    '''
    parser = argparse.ArgumentParser()
    parser.add_argument("-mu", metavar='mu', type=str, nargs='+', help="file containing music features, input to model", default=[])
    parser.add_argument("-mw", metavar='mw', type=str, nargs='+', help="file containing music+walking features, input to model", default=[])
    parser.add_argument("-mo", metavar='mo', type=str, nargs='+', help="file containing movie features, input to model", default=[])
    parser.add_argument("-e", "--estimators", help="number of estimators for meta-classifiers", type=int, default=100)
    parser.add_argument("-o", "--output_file", help="output with pickle results", type=str)
    parser.add_argument("--neutral", action='store_true', help="classify happy-sad-neutral")
    args = parser.parse_args()
    output_file = args.output_file
    N_ESTIMATORS = args.estimators
    neutral = args.neutral

    def process_condition(fnames, condition):
        if not fnames:
            return
        print('condition', condition)

        results = {'labels':[], 'baseline': defaultdict(list),
                   'logit': defaultdict(list), 
                   'rf': defaultdict(list),
                   'gb': defaultdict(list),
                   'cnn': defaultdict(list)}

        for fname in fnames:
            print('classifying: %s' % fname)
            label = fname.split('/')[-1]
            data = np.loadtxt(fname, delimiter=',')
            print(data.shape)

            if not neutral:
                data = np.delete(data, np.where(data[:,-1]==0), axis=0)

            np.random.shuffle(data)

            x_data = data[:,:-1]
            y_data = data[:,-1]

            # Scale features
            x_data = preprocessing.scale(x_data)

            # Prepare models
            models = [
                ('baseline', DummyClassifier(strategy='most_frequent')),
                ('logit', linear_model.LogisticRegression(max_iter=1000)),
                ('rf', RandomForestClassifier(n_estimators=N_ESTIMATORS)),
                ('gb', GradientBoostingClassifier(n_estimators=N_ESTIMATORS))
            ]

            results['labels'].append(label)
            repeats = 2
            folds = 2
            rskf = RepeatedStratifiedKFold(n_splits=folds, n_repeats=repeats, random_state=SEED)

            for key, clf in models:
                scores = {'f1':[], 'acc':[], 'roc_auc':[]}
                for train, test in rskf.split(x_data, y_data):
                    x_train, x_test = x_data[train], x_data[test]
                    y_train, y_test = y_data[train], y_data[test]
                    clf.fit(x_train, y_train)
                    y_pred = clf.predict(x_test)
                    _f1 = metrics.f1_score(y_test, y_pred, average='weighted')
                    _acc = metrics.accuracy_score(y_test, y_pred)
                    y_proba = clf.predict_proba(x_test)
                    _roc_auc = metrics.roc_auc_score(y_test, y_proba[:, 1], average='weighted')
                    scores['f1'].append(_f1)
                    scores['acc'].append(_acc)
                    scores['roc_auc'].append(_roc_auc)

                results[key]['f1'].append(np.mean(scores['f1']))
                results[key]['acc'].append(np.mean(scores['acc']))
                results[key]['roc_auc'].append(np.mean(scores['roc_auc']))

            # CNN Model
            scores_cnn = {'f1':[], 'acc':[], 'roc_auc':[]}
            y_data_categorical = to_categorical(y_data)
            for train, test in rskf.split(x_data, y_data):
                x_train, x_test = x_data[train], x_data[test]
                y_train, y_test = y_data_categorical[train], y_data[test]
                
                x_train_cnn = np.expand_dims(x_train, axis=2)
                x_test_cnn = np.expand_dims(x_test, axis=2)

                model = Sequential()
                model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))
                model.add(GlobalMaxPooling1D())
                model.add(Dense(50, activation='relu'))
                model.add(Dense(y_data_categorical.shape[1], activation='softmax'))
                model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

                model.fit(x_train_cnn, y_train, epochs=10, verbose=0)
                y_pred = model.predict(x_test_cnn)
                y_pred_classes = np.argmax(y_pred, axis=1)
                
                _f1 = metrics.f1_score(y_test, y_pred_classes, average='weighted')
                _acc = metrics.accuracy_score(y_test, y_pred_classes)
                _roc_auc = metrics.roc_auc_score(y_test, y_pred[:, 1], average='weighted')
                scores_cnn['f1'].append(_f1)
                scores_cnn['acc'].append(_acc)
                scores_cnn['roc_auc'].append(_roc_auc)
                print('CNN: ', _f1, _acc, _roc_auc)

            results['cnn']['f1'].append(np.mean(scores_cnn['f1']))
            results['cnn']['acc'].append(np.mean(scores_cnn['acc']))
            results['cnn']['roc_auc'].append(np.mean(scores_cnn['roc_auc']))

        yaml.dump(results, open(condition+'_lift_scores_'+output_file+'.yaml', 'w'))

    if args.mu:
        process_condition(args.mu, 'mu')
    if args.mw:
        process_condition(args.mw, 'mw')
    if args.mo:
        process_condition(args.mo, 'mo')

if __name__ == "__main__":
    main()
