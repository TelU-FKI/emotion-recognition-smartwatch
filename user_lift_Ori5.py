import argparse
import yaml
import numpy as np
from collections import defaultdict

from sklearn import linear_model
from sklearn import metrics
from sklearn import model_selection
from sklearn import preprocessing
from sklearn.dummy import DummyClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RepeatedStratifiedKFold

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical

from permute.core import one_sample

SEED = 1
np.random.seed(SEED)

def create_cnn_model(input_shape, num_classes):
    model = Sequential()
    model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape))
    model.add(Conv1D(64, kernel_size=3, activation='relu'))
    model.add(Flatten())
    model.add(Dense(100, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
    return model

def main():
    '''
    Run as:
    python user_lift.py -mo features/features_mo* -mw features/features_mw* -mu features/features_mu*

    Takes features generated by extract_windows.py script, runs classifier, and prints accuracy results.
    '''
    parser = argparse.ArgumentParser()
    parser.add_argument("-mu", metavar='mu', type=str, nargs='+', help="file containing music features, input to model", default=[])
    parser.add_argument("-mw", metavar='mw', type=str, nargs='+', help="file containing music+walking features, input to model", default=[])
    parser.add_argument("-mo", metavar='mo', type=str, nargs='+', help="file containing movie features, input to model", default=[])
    parser.add_argument("-e", "--estimators", help="number of estimators for meta-classifiers", type=int, default=100)
    parser.add_argument("-o", "--output_file", help="output with pickle results", type=str)
    parser.add_argument("--neutral", action='store_true', help="classify happy-sad-neutral")
    args = parser.parse_args()
    output_file = args.output_file
    N_ESTIMATORS = args.estimators
    neutral = args.neutral

    def process_condition(fnames, condition):

        if not fnames: 
            return
        print('condition', condition)

        results = {'labels':[], 'baseline': defaultdict(list),
                    'logit': defaultdict(list), 
                    'rf': defaultdict(list),
                    'cnn': defaultdict(list)}

        for fname in fnames:
            print('classifying: %s' % fname)
            label = fname.split('/')[-1]

            data = np.loadtxt(fname, delimiter=',')

            if not neutral:
                # delete neutral to see if we can distinguish between
                # happy/sad
                data = np.delete(data, np.where(data[:,-1]==0), axis=0)

            np.random.shuffle(data)

            x_data = data[:,:-1]
            y_data = data[:,-1]

            # scaled
            x_data = preprocessing.scale(x_data)
            num_classes = len(np.unique(y_data))
            y_data = to_categorical(y_data, num_classes=num_classes)

            models = [
                    ('baseline', DummyClassifier(strategy = 'most_frequent')),
                    ('logit', linear_model.LogisticRegression(max_iter=1000)),
                    ('rf', RandomForestClassifier(n_estimators = N_ESTIMATORS)),
                    ]

            input_shape = (x_data.shape[1], 1)
            cnn_model = create_cnn_model(input_shape, num_classes)
            models.append(('cnn', cnn_model))

            results['labels'].append(label)
            repeats = 10
            folds = 10
            rskf = RepeatedStratifiedKFold(n_splits=folds, 
                                        n_repeats=repeats,
                                        random_state=SEED)

            for key, clf in models:
                scores = {'f1':[], 'acc':[], 'roc_auc':[]}
                for i, (train,test) in enumerate(rskf.split(x_data, y_data.argmax(axis=1))):
                    x_train, x_test = x_data[train], x_data[test]
                    y_train, y_test = y_data[train], y_data[test]

                    if key == 'cnn':
                        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))
                        x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))
                        clf.fit(x_train, y_train, epochs=10, verbose=0)
                        y_pred = clf.predict(x_test)
                        y_pred_classes = y_pred.argmax(axis=1)
                        y_test_classes = y_test.argmax(axis=1)
                    else:
                        clf.fit(x_train, y_train.argmax(axis=1))
                        y_pred_classes = clf.predict(x_test)
                        y_test_classes = y_test.argmax(axis=1)
                        y_pred = clf.predict_proba(x_test)
                    
                    _f1 = metrics.f1_score(y_test_classes, y_pred_classes, average='weighted')
                    _acc = metrics.accuracy_score(y_test_classes, y_pred_classes)
                    _roc_auc = metrics.roc_auc_score(y_test_classes, y_pred, multi_class='ovr', average='weighted')
                    scores['f1'].append(_f1)
                    scores['acc'].append(_acc)
                    scores['roc_auc'].append(_roc_auc)

                results[key]['f1'].append(np.mean(scores['f1']))
                results[key]['acc'].append(np.mean(scores['acc']))
                results[key]['roc_auc'].append(np.mean(scores['roc_auc']))

        yaml.dump(results, open(condition+'_lift_scores_'+output_file+'.yaml', 'w'))

    # end of function
    #-------------

    if args.mu:
        process_condition(args.mu, 'mu')
    if args.mw:
        process_condition(args.mw, 'mw')
    if args.mo:
        process_condition(args.mo, 'mo')


if __name__ == "__main__":
    main()
